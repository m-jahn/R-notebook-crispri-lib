---
title: "Enzyme utilization and saturation for *R. eutropha*"
date: "`r format(Sys.time(), '%d %B, %Y')`"
output:
  html_notebook: 
    theme: spacelab
    toc: yes
---


## Description

This R notebook is a bioinformatics pipeline to **analyze protein saturation/under-utilization with a resource allocation model** for the chemolithoautotroph *Ralstonia eutropha* (a.k.a. *Cupriavidus necator*).


## Libraries

```{r, message = FALSE}
# loading libraries
library(lattice)
library(latticeExtra)
library(latticetools)
library(tidyverse)
library(stringi)
```

## Data import

Define the data source directories. Some of them are external in the sense of not included in the accompanying data folder of this R notebook. These are located in the accompanying github repository for the resource allocation model that was used here. The resource allocation model can be found at my fork of [Bacterial-RBA-models](https://github.com/m-jahn/Bacterial-RBA-models).

```{r, message = FALSE}
Reutropha_proteomics <- "~/Documents/SciLifeLab/Resources/R_projects/ShinyProt/data/Ralstonia_eutropha.Rdata"
model_reactions <- "~/Documents/SciLifeLab/Resources/Models/genome-scale-models/Ralstonia_eutropha/simulations/essentiality/model_reactions.csv"
simulation_dir <- "~/Documents/SciLifeLab/Resources/Models/Bacterial-RBA-models/Ralstonia-eutropha-H16/simulation/substrate_limitation/"
source("read_rba_result.R")
```


Read simulation data.

```{r}
# read simulation results
df_flux <- read_rba_result(list.files(simulation_dir, pattern = "fluxes_.*.tsv$", full.names = TRUE))
df_prot <- read_rba_result(list.files(simulation_dir, pattern = "proteins_.*.tsv", full.names = TRUE))
df_macr <- read_rba_result(list.files(simulation_dir, pattern = "macroprocesses_.*.tsv", full.names = TRUE))
```


## Overview on substrate uptake, growth, and yield

After running a set of simulations in RBApy that simulate increasing substrate limitation, we can plot the substrate uptake rate `q`, yield `Y` in gram biomass per gram substrate, and growth rate `µ`. Unlike genome scale models, growth becomes limited by the maximum amount of proteins that a cell can synthesize. If cells would not be protein-limited, *or* proteins would catalyze reactions infinitely fast, no such limitation would take place and growth rate would scale linearly with substrate concentration. This is the situation in FBA simulation.

```{r, fig.width = 6.7, fig.height = 6.7, message = FALSE, warning = FALSE}
# add g per gDCW uptake rate
df_macr <- df_macr %>% mutate(
  substrate_conc_g = case_when(
    carbon_source == "for" ~ carbon_conc * 0.04603,
    carbon_source == "succ" ~ carbon_conc * 0.11809,
    carbon_source == "fru" & nitrogen_conc == 1 ~ carbon_conc * 0.18016,
    carbon_source == "fru" & nitrogen_conc != 1 ~ nitrogen_conc * 0.05349
  )
)

# Herbet-Pirt-plot function to create plots using different parameters
HP_plot <- function(data, xvar, yvar, condvar, 
  xlimits = c(0, 0.3), ylimits = c(0, 1)
) {
  xyplot(get(yvar) ~ get(xvar) | get(condvar), data,
    par.settings = custom.colorblind(), lwd = 1.5,
    xlim = xlimits, ylim = ylimits,
    ylab = expression("q"[S]*" [g h"^-1*" gDCW"^-1*"]"),
    xlab = expression('µ [h'^'-1'*']'),
    panel = function(x, y, ...) {
      panel.grid(h = -1, v = -1, col = grey(0.9))
      panel.xyplot(x, y, cex = 0.9, ...)
      # regression line through linear part of the data
      panel.lmlineq(x, y, fontfamily = "FreeSans", 
        pos = 3, offset = 7, r.squared = TRUE, cex = 0.7, col.text = grey(0.3), ...)
      coef <- lm(y ~ x, data.frame(x, y))$coeff
      # displaying maintenance and yield coefficients
      panel.abline(h = coef[[1]], lty = 2, ...)
      panel.text(0.15, coef[[1]], 
        paste("ms =", round(coef[[1]], 3), "g h-1 g_DCW-1"), 
        col = grey(0.3), pos = 3, cex = 0.7)
      panel.text(0.15, coef[[1]], paste(expression("Yx/S ="), 
          round(1/coef[[2]], 3), "g_DCW g_S-1"), 
        col = grey(0.3), pos = 1, cex = 0.7)
    }
  )
}

print(HP_plot(data = filter(df_macr, carbon_source == "for", key == "mu"), 
  xvar = "value", yvar = "substrate_conc_g", condvar = "carbon_source", 
  ylimits = c(-5/4, 5)), split = c(1,1,2,2), more = TRUE)

print(HP_plot(data = filter(df_macr, carbon_source == "fru" & nitrogen_conc == 1, key == "mu"), 
  xvar = "value", yvar = "substrate_conc_g", condvar = "carbon_source",
  ylimits = c(-1/4, 1)), split = c(2,1,2,2), more=TRUE)

print(HP_plot(data = filter(df_macr, carbon_source == "fru" & nitrogen_conc != 1, key == "mu"), 
  xvar = "value", yvar = "substrate_conc_g", condvar = "nitrogen_source",
  ylimits = c(-0.23/4, 0.15)), split = c(1,2,2,2), more = TRUE)

print(HP_plot(data = filter(df_macr, carbon_source == "succ", key == "mu"), 
  xvar = "value", yvar = "substrate_conc_g", condvar = "carbon_source",
  ylimits = c(-1/4, 1)), split = c(2,2,2,2))
```


```{r, include = FALSE}
# export figure
svg("../figures/figure_substrate_limitation.svg", width = 6.7, height = 6.7)
print(HP_plot(data = filter(df_macr, carbon_source == "for", key == "mu"), 
  xvar = "value", yvar = "substrate_conc_g", condvar = "carbon_source", 
  ylimits = c(-5/4, 5)), split = c(1,1,2,2), more = TRUE)

print(HP_plot(data = filter(df_macr, carbon_source == "fru" & nitrogen_conc == 1, key == "mu"), 
  xvar = "value", yvar = "substrate_conc_g", condvar = "carbon_source",
  ylimits = c(-1/4, 1)), split = c(2,1,2,2), more=TRUE)

print(HP_plot(data = filter(df_macr, carbon_source == "fru" & nitrogen_conc != 1, key == "mu"), 
  xvar = "value", yvar = "substrate_conc_g", condvar = "nitrogen_source",
  ylimits = c(-0.23/4, 0.15)), split = c(1,2,2,2), more = TRUE)

print(HP_plot(data = filter(df_macr, carbon_source == "succ", key == "mu"), 
  xvar = "value", yvar = "substrate_conc_g", condvar = "carbon_source",
  ylimits = c(-1/4, 1)), split = c(2,2,2,2))
dev.off()
```


## Resource allocation in terms of protein mass

To determine the true allocation of protein resources per compartment, but also the true cost of protein per process, we need to **convert the predicted concentration of proteins in mmol per gDCW to g per gDCW**, simply by multiplying protein concentration with the molecular weight of a protein (g/mol, converted to g/mmol). We can then also easily transform g/gDCW to mass fraction by dividing individual protein concentrations by the sum of all protein concentrations. The protein mass fraction is dimensionless. The only parameter required for this transformation is the molecular weight per protein which is available from uniprot. We can for example take the protein annotation table that is automatically downloaded during `RBApy` model generation.

```{r, message = FALSE}
# import downloaded Ralstonia protein annotation from uniprot
df_uniprot <- read_tsv(paste0(simulation_dir, "../../data/uniprot.csv"), col_types = cols()) %>%
  mutate(locus_tag = stri_extract_first(`Gene names`, regex = "H16_[AB][0-9]{4}|PHG[0-9]{3}"))

# merge predicted protein allocation with molecular weight info from uniprot
df_prot <- left_join(df_prot, select(df_uniprot, locus_tag, Length, Mass),
  by = c("key" = "locus_tag")) %>%
  
  # calculate predicted protein mass in g/gDCW using MW in g/mmol, and mass fraction
  group_by(simulation) %>% mutate(
    predicted_mass_g_gDCW = value * Mass / 1000)

# test if mass fractions sum to reasonable value
df_prot %>% summarize(
  predicted_mass_g_gDCW = sum(predicted_mass_g_gDCW, na.rm = TRUE))
```

----------

The simulated protein mass per gDCW changes with growth rate, and it is considerably lower then the estimated ~0.65-0.68 g total protein/gDCW that was previously estimated for bacteria (see e.g. Park et al., biomass composition for *Ralstonia eutropha* model, or Touloupakis et al., biomass composition for cyanobacteria). One reason is that above numbers only include enzymatic proteins (the ones represented by the GSM). For machinery such as ribosomal proteins, a separate calculation needs to be performed. The model returns estimated concentration of machineries for replication, transcription, translation, and protein folding. The associated proteins can be imported from the model folder and the total mass estimated using molecular weight and subunit stoichiometry as done before for enzymatic proteins.

```{r, message = FALSE}
machinery_names <- c("replication", "transcription", "ribosome", "chaperones")
machinery_tables <- paste0(simulation_dir, "../../data/", machinery_names, ".tsv")

df_macr <- df_macr %>% group_by(simulation) %>%
  mutate(
    key = recode(key, !!!setNames(machinery_names, c("P_REP", "P_TSC" , "P_TA", "P_CHP"))),
    substrate_uptake_rate = value[key == "qS"],
    predicted_growth_rate = value[key == "mu"],
  )

df_machinery <- lapply(machinery_tables, read_tsv) %>% bind_rows(.id = "machine") %>%
  mutate(machine = recode(machine, !!!setNames(machinery_names, 1:4))) %>%
  select(-`Entry name`, -Sequence, -Cofactor, -`EC number`, -`Organism ID`, `Organism`,
    -`Catalytic activity`, -Status) %>%
  
  # join with prediction of molecular machine concentration (mmol/gDCW)
  left_join(df_macr, by = c("machine" = "key")) %>%
  
  # calculate predicted protein mass in g/gDCW using MW in g/mmol, and mass fraction
  group_by(simulation) %>% mutate(
    predicted_mass_g_gDCW = value * Stoichiometry * Mass / 1000
  )

# test if mass fractions sum to reasonable value
df_machinery %>% summarize(
  sum_g_gDCW = sum(predicted_mass_g_gDCW, na.rm = TRUE))
```

If the utilized protein for enzymes and machinery is summed up, it does not exceed ~0.25 g/gDCW. The reason for this is that up to 60% of the protein mass is not modeled (non enzymatic, NE proteome, 57.7% at µ = 0, see R notebook `Ralstonia-model-constraints`), and only around 68% of the total cell mass is protein. If we consider this, than total protein mass can be estimated as m = 0.25/(1-0.6) = `r round(0.25/(1-0.6), 3)` g/gDCW. This is much closer to the estimated 0.68 g protein/gDCW. The difference can be attributed to default values of amino acid concentration in `RBApy` that determine the size of the 'protein pool'. It is important to note that the sum of utilizable proteins is not a constant value but a linear function of growth rate. The total proteome pool *including non-enzymatic proteins* is, however, constant.


## Correlation between predicted and experimentally determined proteome

To compare the predicted and experimental proteome composition, we load the required proteomics data. Proteomics data are mass spectrometry measurements with label-free quantification of peptides. Protein quantification was performed by summing up all peptide intensities per annotated protein. The proteomic measurement unit, mass fraction, can be easily transformed to g/gDCW by multiplying mass fraction with the total protein mass (g/gDCW) from the RBApy simulation. Or *vice versa* by converting RBApy protein concentration to mass fraction.

To allow a fair comparison between measured and predicted data, it is necessary to aggregate (e.g. sum up) all protein abundances allocated of one reaction. The reason is that the model will only predict **protein abundance of the first of a range of iso-enzymes** for a particular reaction, while in reality another iso-enzyme might be more abundant (carry the majority of flux). This would lead to lower correlation between measured and predicted protein concentrations. This is not necessary for machinery proteins.


### Combine simulations and experimental data

The proteomics data has to be merged with `RBApy` simulation results using matching conditions. First, proteomics data has to be loaded and prepared for merging.


**Step 1: load proteomics data**

```{r}
load(Reutropha_proteomics)

# pick a condition matching simulations
Ralstonia_eutropha <- Ralstonia_eutropha %>%
  
  # select only required columns
  rename(growth_rate = growthrate) %>%
  select(uniprot, locus_tag, protein, condition, substrate, substrate_uptake_rate,
    growth_rate, COG_Process, R1:R4) %>%
  
  # turn raw intensity measurements into mass in g per gDCW (assuming a 
  # total protein concentration of 0.68 g/gDCW)
  group_by(condition) %>%
  mutate(across(matches("R[1234]"), function(x) x/sum(x, na.rm = TRUE)*0.68)) %>%
  gather(key = "replicate", value = "mass_g_gDCW", R1:R4)
```


**Step 2: Load gene reaction associations obtained from genome scale model**

```{r, warning = FALSE}
df_model_reactions <- read_csv(model_reactions, col_types = cols()) %>%
  
  # filter for reactions with gene associations
  select(reaction_id, reaction_name, genes, groups) %>% separate_rows(genes, sep = ", ") %>%
  filter(!is.na(genes)) %>% 
  rename(model_group = groups) %>%
  
  # add a more general groups description
  mutate(model_group_basic = case_when(
    grepl("Phenylala|Valine|Tyrosine|Glutamate|Glycine|Tryptophan|Methionine|
          Cysteine|Alanine|Histidine|Arginine|Lysine", model_group) ~ "Amino acid",
    grepl("Pentose|Calvin", model_group) ~ "PPP + Calvin cycle",
    model_group == "Citric Acid Cycle" ~ "Citric Acid Cycle",
    model_group == "Glycolysis/Gluconeogenesis" ~ "Glycolysis/Gluconeogenesis",
    model_group == "Glyoxylate and Dicarboxylate metabolism" ~ "Autotrophic energy",
    model_group == "Oxidative Phosphorylation" ~ "Oxidative Phosphorylation",
    TRUE ~ "Other"
  ))
```


**Step 3: Select and rename conditions from RBA simulation**

```{r}
# add type of substrate limitation
add_cond <- function(df) {
  df %>% mutate(substrate = case_when(
    carbon_source == "succ" ~ "succinate",
    carbon_source == "for" ~ "formate",
    carbon_source == "fru" & nitrogen_conc == 1 ~ "fructose",
    TRUE ~ "ammonium",
  ))
}

# add substrate uptake rate
add_qS <- function(df) {
  df %>% mutate(substrate_uptake_rate = case_when(
    nitrogen_conc == 1 ~ carbon_conc,
    nitrogen_conc != 1 ~ nitrogen_conc
  ))
}

df_machinery <- df_machinery %>% add_cond
df_prot <- df_prot %>% add_cond %>% add_qS
df_flux <- df_flux %>% add_cond %>% add_qS
```


**Step 4: Merge protein measurements and predictions into master tables**

The first step is to merge the tables for machinery proteins, that means proteins related to replication, transcription, translation, and protein folding. These don't require allocation of protein mass to reactions, and merging becomes simply an operation on enzyme IDs and conditions.

```{r}
# join with proteomics data
df_machinery <- left_join(
  df_machinery, Ralstonia_eutropha,
  by = c("Entry" = "uniprot", "substrate", "substrate_uptake_rate"))
```

The second table for all enzymatic proteins requires the allocation of estimated protein mass to enzymes.
One option for the future is to retrieve these values directly from RBApy, but this is not implemented yet.

```{r, message = FALSE}
df_prot_comp <- df_model_reactions %>%
  
  # join with proteomics data
  left_join(Ralstonia_eutropha, by = c("genes" = "locus_tag")) %>%
  
  # join with simulation data
  left_join(df_prot, by = c("genes" = "key", "substrate", "substrate_uptake_rate")) %>%
  
  # determine number of reactions per protein
  group_by(condition, genes, replicate) %>% 
  mutate(n_reactions = length(reaction_id)) %>%
  
  # calculate protein mass in g/gDCW
  group_by(condition) %>% mutate(
    predicted_mass_g_gDCW = predicted_mass_g_gDCW/n_reactions,
    mass_g_gDCW = mass_g_gDCW/n_reactions
  ) %>%
  
  # summarize by summing up protein abundance per reaction (NA treated as zero)
  group_by(condition, reaction_id, reaction_name, model_group, model_group_basic, substrate, substrate_uptake_rate,
    growth_rate, replicate) %>% 
  summarize(
    predicted_mass_g_gDCW = sum(predicted_mass_g_gDCW, na.rm = TRUE),
    mass_g_gDCW = sum(mass_g_gDCW, na.rm = TRUE)
  ) %>%
  
  # add predicted growth rate to experimental
  left_join(
    df_machinery %>% ungroup %>%
    select(substrate, substrate_uptake_rate, predicted_growth_rate) %>%
    filter(!duplicated(substrate_uptake_rate))
  ) %>%
  
  # add predicted fluxes per reaction and condition
  left_join(
    df_flux %>% ungroup %>%
    select(key, value, substrate, substrate_uptake_rate) %>%
    rename(reaction_id = key, flux_mmol_gDCW_h = value)
  )
```

Now we perform a test. We check if all protein abundances allocated to reactions sum to a reasonable value as we would expect. This value would be the total *enzymatic* protein mass in g/gDCW, per condition and replicate, and could reach up to 0.2 g/gDCW for the simulations, and higher for the actual data (includes additional protein quantified in experiment, but not carrying flux in model simulations).

```{r, message = FALSE}
df_prot_comp %>% group_by(condition, replicate) %>% 
  filter(predicted_mass_g_gDCW != 0) %>%
  summarize(sum(mass_g_gDCW), sum(predicted_mass_g_gDCW))
```

----------

The total predicted protein mass is lower than the measured protein mass. Therefore the following section quantifies discrepancies between model predicted and actually measured abundances. First we can inspect the top N reactions with highest **average predicted protein abundance**. The ratio of predicted divided by measured mass indicates that a handful of proteins are predicted to be more than 10 fold abundant compared to the measured abundance. This points towards fluxes being erroneously predicted too high for particular reactions, or *k_app* values being estimated too low for the estimated flux. 

However, the largest discrepancies arise from **under-estimation of proteins**, the main cause being that the model predicts the **optimal abundance for each enzyme to carry a certain flux** (see following figure, comparison of simulation and experiment). If fluxes are drastically reduced due to strong substrate limitation, the minimal required protein abundance to optimize growth will be much lower than the measured abundance. The cell on the other hand does not reduce it's proteome but instead 'suspends' enzymes.


```{r, message = FALSE, fig.height = 8, fig.width = 8}
# Proteins 'over-predicted' by more than 10x are rare
df_prot_comp %>% group_by(reaction_id, substrate) %>%
  summarize(
    average_predicted_mass = mean(predicted_mass_g_gDCW),
    average_measured_mass = mean(mass_g_gDCW),
    overprediction_fold = round(average_predicted_mass/average_measured_mass)) %>%
  arrange(desc(overprediction_fold)) %>% filter(overprediction_fold > 10)

# comparison of simulation and experiment
df_prot_comp %>% group_by(reaction_id, substrate, growth_rate) %>%
  summarize(predicted_mass_g_gDCW = mean(predicted_mass_g_gDCW),
    mass_g_gDCW = mean(mass_g_gDCW)
  ) %>%
  
  xyplot(log10(predicted_mass_g_gDCW) ~ log10(mass_g_gDCW) | factor(growth_rate) * substrate, .,
    groups = substrate,
    par.settings = custom.colorblind(), cex = 0.7,
    scales = list(alternating = FALSE), as.table = TRUE,
    between = list(x = 0.5, y = 0.5), 
    pch = 1, xlim = c(-8.5, -0.5), ylim = c(-8.5, -0.5),
    panel = function(x, y, ...) {
      panel.grid(h = -1, v = -1, col = grey(0.9))
      panel.abline(a = 0, b = 1, col = grey(0.5), lty = 2, lwd = 2)
      panel.xyplot(x, y, ...)
    }
  )
```

### Change of machinery proteins over growth rate

The simulation and measurement data was prepared and merged by condition in the previous sections. Now it can be plotted to e.g. compare protein allocation over growth rate. Interestingly, we see that model predictions are quite accurately reflecting the range of protein allocation for the four different machineries, see following paragraphs. This is a good confirmation of the model's predictive power, given that the rates of these machineries were not fitted from data but taken purely from literature.  There are however some deviations from the predicted 'optimal' proteome:

- the most important machine is the ribosome. Prediction and experiment show a very similar increase of ribosome abundance with growth rate, but the intersection (amount of unused ribosomes) is much higher in experiment
- chaperones show an inverse proportional relationship with growth rate contrary to model prediction. Do (some of?) these proteins have another role than just folding, like stress response?
- transcription sector is quite stable, however, requires more enzymes than expected. Abundance is underestimated by 1 order of magnitude (5x10^-3 vs 5x10^-4 g/gDCW)
- replication sector is heavily underestimated by 3 orders of magnitude (10^-3 vs 10^-6 g/gDCW)

The following code section gathers growth rate/mass measurements and predictions in a single column each. This is better for summarizing and plotting.

```{r, echo = FALSE}
# A generalized plotting function to save some repetition
xyplot_errbars <- function(
  data, variables, groups = NULL,
  xlim = NULL, ylim = NULL,
  xlab = expression("µ [h"^-1*"]"),
  ylab = expression("m"[protein]*" [g gDCW"^-1*"]")) {
  
  scaleoptions <- list(alternating = FALSE)
  if (!is.null(xlim)) scaleoptions$x = list(limits = xlim)
  if (!is.null(ylim)) scaleoptions$y = list(limits = ylim)
  
  xyplot(as.formula(variables), data,
    groups = {if (!is.null(groups)) get(groups) else NULL},
    par.settings = custom.colorblind(),
    scales = scaleoptions, as.table = TRUE,
    between = list(x = 0.5, y = 0.5),
    pch = 19, lwd = 2, 
    xlab = xlab, ylab = ylab,
    panel = function(x, y, ...) {
      panel.grid(h = -1, v = -1, col = grey(0.9))
      panel.errbars(x, y, ewidth = 0, ...)
      panel.key(..., cex = 0.7)
      panel.superpose(x, y, ...)},
    panel.groups = function(x, y, ...) {
      panel.lmline(x, y, ...)
    }
  )
}
```


```{r, message = FALSE, fig.width = 6, fig.height = 6.8}
df_machinery %>%
  
  # summing up protein mass over all conditions
  group_by(machine, substrate, growth_rate, replicate) %>%
  summarize(
    mass_g_gDCW = sum(mass_g_gDCW, na.rm = TRUE),
    predicted_mass_g_gDCW = sum(predicted_mass_g_gDCW, na.rm = TRUE)
  ) %>%
  
  # replace 0 with NA and reorder factors
  mutate(across(matches("mass_g_gDCW"), ~ na_if(.x, 0))) %>%
  mutate(machine = factor(machine, unique(machine)[c(2,4,3,1)])) %>%
  
  xyplot_errbars(
    variables = "mass_g_gDCW + predicted_mass_g_gDCW ~ 
      factor(growth_rate) | machine * substrate"
  )
```
The increase of chaperone proteins with decreasing growth rate is counter-intuitive, and the underlying cause might be the inclusion or exclusion of particular proteins in this group. We want to include mostly chaperones related to the primary ribosome-supporting task of polypeptide chain folding after translation. Chaperones that are mostly related to stress-resistance or environmental resilience should be excluded (upregulated under substrate limitation?). The following plot shows abundance over growth rate for single proteins within a machinery, such as chaperones.

```{r, fig.width = 8, fig.height = 4, fig.align = "center"}
xyplot_errbars(
  data = df_machinery %>% filter(machine == "chaperones"),
  variables = "mass_g_gDCW ~ factor(growth_rate) | substrate",
  groups = "protein"
)
```

### Change of enzymatic proteins over growth rate

Similar to machinery proteins we can also follow the simulation and actual protein abundance of all (detected) enzymes. The first step is to construct different **groups of interesting reactions** that can be inspected closer.

The next step is to have a generalized plotting function that can plot simulated and measured protein abundance including error bars. We can see that some protein abundances nicely follow a growth-rate dependent manner, in line with predictions of higher flux. One such example are Calvin cycle enzymes for fromatotrophic growth. However, for the same enzymes we see that no abundance is predicted under heterotrophic conditions because of missing flux through the pathway, but in fact the proteins are expressed in high abundance, often in a growth-rate dependent manner. What is also puzzling is abundances for most enzymes are actually under-predicted. Since the total amount of enzymatic protein is comparable (but not identical) for simulations and measurements, we also have to investigate over-predicted protein abundances.

```{r, message = FALSE, fig.width = 9, fig.height = 5.5}
# Plot Calvin cycle reactions
calvin = c("FDH", "RBPC", "PGK", "GAPD", "TPI", "FBA", "FBP", "TKT2", "TKT1", "TAh", "RPE", "RPI")

xyplot_errbars(
  data = df_prot_comp %>% filter(reaction_id %in% calvin),
  variables = "mass_g_gDCW + predicted_mass_g_gDCW ~ 
    factor(growth_rate) | reaction_id * substrate",
  ylim = c(-0.002, 0.032)
)
```

----------

## Determining under-utilization of proteins

It is clear from the previous analysis that the cells maintain proteins even if they are not or only marginally utilized. The actually utilized proteome is minimal under strong substrate limitation. The next section will try to quantify the **under-utilization of enzymes** by determining e.g. the flux per enzyme and compare minimal protein requirement (simulation) versus measured protein abundance.

A second option is to simply compare **trends in enzyme saturation** and derive conclusions about the underlying regulation of enzyme abundance. We can think of the following scenarios:

- enzyme abundance expands with growth rate/flux in experiment and simulation. Utilization is constant, protein allocation is optimized towards flux and may exert some control over a pathway
- enzyme abundance is constant in experiment, regardless of flux in simulation. Utilization increases with growth rate. 'housekeeping' protein with non-limiting concentration, less probability for control over pathway
- enzyme abundance is inversely correlated with growth rate, while simulation is constant or positively correlated with growth rate. Enzyme involved in environmental response, readiness.

Note that this analysis only includes enzymes that are **actually utilized by the model** under some condition, not all proteins included in the model or all experimentally quantified proteins. This is covered in the R notebook **Ralstonia_variability_analysis**.

### Under-utilization by protein abundance

For this branch of analysis, it is sufficient to determine the underutilized protein fraction (of all utilized proteins) by subtracting the simulated optimal protein allocation from the experimentally measured.

```{r, message = FALSE, fig.width = 9, fig.height = 5.5}
df_prot_comp <- df_prot_comp %>%
  
  # calculate (un)-utilized protein mass and fraction
  mutate(
    unutilized_mass_g_gDCW = mass_g_gDCW - predicted_mass_g_gDCW,
    unutilized_mass_fraction = unutilized_mass_g_gDCW/mass_g_gDCW,
  )
```

----------

Plot under-utilized proteins by pathway.

```{r, message = FALSE, fig.width = 9, fig.height = 5.5}
xyplot_errbars(
  data = df_prot_comp %>% filter(reaction_id %in% calvin),
  variables = "unutilized_mass_g_gDCW ~ factor(growth_rate) | reaction_id * substrate",
  groups = "substrate", ylim = c(-0.003, 0.023)
)
```

----------

The following plot is a summary of underutilized enzyme mass *per condition* instead of pathway. Included are only reactions that carry flux under at least one condition or growth rate (that means reactions that never carry flux in any simulation are removed).

```{r, fig.width = 6, fig.height = 5, message = FALSE}
plot_underutil_by_cond <- df_prot_comp %>% group_by(reaction_id) %>%
  filter(sum(predicted_mass_g_gDCW) > 0) %>%
  
  # sum up underutilized mass per substrate and growth rate
  group_by(substrate, substrate_uptake_rate, growth_rate, replicate) %>%
  summarize(
    sum_underutilized_mass_g_gDCW = sum(unutilized_mass_g_gDCW, na.rm = TRUE),
    sum_utilized_mass_g_gDCW = sum(predicted_mass_g_gDCW, na.rm = TRUE)
  ) %>%
  
  #replace zero with NA
  mutate(sum_underutilized_mass_g_gDCW = sum_underutilized_mass_g_gDCW %>%
    replace(., . <= 0, NA)) %>%
  
  xyplot(sum_underutilized_mass_g_gDCW + sum_utilized_mass_g_gDCW ~ 
    factor(growth_rate) | substrate, .,
    par.settings = custom.colorblind(),
    xlab = expression(µ*" [h"^-1*"]"),
    ylab = expression("m"[protein]*" [g gDCW"^-1*"]"),
    ylim = c(0, 0.27),
    scales = list(alternating = FALSE), as.table = TRUE,
    between = list(x = 0.5, y = 0.5), 
    ewidth = 0.15, beside = TRUE, lwd = 1.5,
    panel = function(x, y, errors, ...) {
      panel.grid(h = -1, v = -1, col = grey(0.9))
      panel.barplot(x, y, ...)
      panel.key(..., cex = 0.7, points = FALSE)
    }
  )

print(plot_underutil_by_cond)
```

The most interesting figure is probably a comparison between different pathways. For this purpose we can use the unambiguous pathway annotation for each reaction contained in the genome scale model. Each reaction is mapped to one pathway only, however, the gene associated to this reaction can be associated with other reactions and then the protein mass is shared/distributed between those.
Included are only reactions that carry flux under at least one condition or growth rate (that means reactions that never carry flux in any simulation are removed). For this figure **only the highest tested growth rate** µ = 0.25 h-1 was selected.

```{r, , fig.width = 7.5, fig.height = 3.7, message = FALSE}
plot_underutil_by_pw <- df_prot_comp %>%
  
  # filter out all reactions that never carry flux under any condition
  group_by(reaction_id) %>%
  filter(sum(predicted_mass_g_gDCW) > 0) %>%
  filter(growth_rate == 0.25) %>%
  
  # summarize the total amount of underutilized protein mass per pathway
  group_by(substrate, model_group_basic, replicate) %>%
  summarize(
    sum_underutilized_mass_g_gDCW = sum(unutilized_mass_g_gDCW, na.rm = TRUE),
    sum_utilized_mass_g_gDCW = sum(predicted_mass_g_gDCW, na.rm = TRUE)
  ) %>%
  
  # filter and reorder pathways by unutilized mass
  group_by(model_group_basic) %>%
  ungroup %>% arrange(desc(sum_underutilized_mass_g_gDCW)) %>%
  mutate(model_group_basic = model_group_basic %>% factor(., unique(.))) %>%
  
  xyplot(sum_underutilized_mass_g_gDCW + sum_utilized_mass_g_gDCW ~ model_group_basic | substrate, .,
    xlab = "",
    ylab = expression("m"[protein]*" [g gDCW"^-1*"]"),
    layout = c(4,1),
    par.settings = custom.colorblind(), ylim = c(-0.002, 0.062),
    scales = list(alternating = FALSE, x = list(rot = 30, cex = 0.7)), as.table = TRUE,
    between = list(x = 0.5, y = 0.5),
    ewidth = 0.15, beside = TRUE, lwd = 1.5,
    panel = function(x, y, ...) {
      panel.grid(h = -1, v = -1, col = grey(0.9))
      panel.barplot(x, y, ...)
      panel.key(c("utilized protein (model)", "under-utilized protein"), 
        cex = 0.7, points = FALSE, corner = c(0.95,0.95))
    }
  )

print(plot_underutil_by_pw)
```

### Trends in protein utilization hint towards flux control

The first task is to make a simple assessment of trends in protein abundance for simulation and experimental results.
One completely supervised strategy could for example entail the summary of each reaction's protein abundance over growth rate by fitting a linear regression model. One could then coarsely cluster (or hand pick) groups of proteins that will

- increase in simulation, increase in experiment (TRUE POSITIVE)
- remain constant in simulation, decrease/are constant in experiment (TRUE NEGATIVE)
- remain constant in simulation, increase in experiment (FALSE POSITIVE)
- increase in simulation, decrease/are constant in experiment (FALSE NEGATIVE)

One additional layer of complexity is that this analysis can be performed for all four available substrate limitations. The individual trends for one or the other limitation might be different for the same protein. We can group the data by reaction and substrate limitation and fit a model over five growth rates and four replicates (20 data points). The slope, intercept and ANOVA p-value can be extracted for experimental protein abundance. For model simulations, the slope is sufficient as intercept is likely zero, and p-value unnecessary to determine due to the inherent linearity of model predictions versus growth rate.

```{r, fig.width = 5, fig.height = 5, message = FALSE}
df_clusters <- df_prot_comp %>%
  
  ungroup %>%
  filter(!(is.na(mass_g_gDCW) | is.na(substrate))) %>%
  
  group_by(model_group_basic, model_group, reaction_id, substrate) %>%
  arrange(desc(growth_rate)) %>%
  summarize(
    average_mass_g_gDCW = mean(mass_g_gDCW[17:20], na.rm = TRUE),
    lin_reg_slope = summary(lm(mass_g_gDCW ~ growth_rate))$coef[2],
    lin_reg_pvalue = summary(lm(mass_g_gDCW ~ growth_rate))$coef[8],
    model_slope = summary(lm(predicted_mass_g_gDCW ~ growth_rate))$coef[2]
  ) %>%
  
  # manual 'clustering' based on protein vs growth rate slope
  mutate(cluster = case_when(
    lin_reg_slope >  0 & model_slope >  0 ~ "growth function",
    lin_reg_slope <= 0 & model_slope <= 0 ~ "readiness function",
    lin_reg_slope >  0 & model_slope <= 0 ~ "unmodeled growth function",
    lin_reg_slope <= 0 & model_slope >  0 ~ "housekeeping function"
  ))
```


```{r, fig.width = 7.5, fig.height = 3.7, message = FALSE}
# number of reactions and total protein mass per 'cluster'
plot_underutil_clusters <- df_clusters %>%
  group_by(substrate, cluster, model_group_basic) %>%
  summarize(average_mass_g_gDCW = sum(average_mass_g_gDCW)) %>%
  ungroup %>% arrange(desc(average_mass_g_gDCW)) %>%
  mutate(model_group_basic = model_group_basic %>% factor(., unique(.))) %>%
  
  xyplot(average_mass_g_gDCW ~ factor(cluster) | substrate, .,
    par.settings = custom.colorblind(),
    groups = model_group_basic, layout = c(4, 1),
    col = colorRampPalette(c("#E7298A", "#66A61E", "#E6AB02"))(7),
    xlab = "", ylab = expression("m"[protein]*" [g gDCW"^-1*"]"),
    ylim = c(0, 0.2), border = grey(0.85),
    scales = list(alternating = FALSE, x = list(rot = 25)), as.table = TRUE,
    between = list(x = 0.5, y = 0.5),
    ewidth = 0.15, beside = TRUE, lwd = 1,
    panel = function(x, y, subscripts, groups, col = col, ...) {
      panel.key(groups = groups, subscripts = subscripts, 
        cex = 0.6, points = FALSE, col = col)
      panel.grid(h = -1, v = -1, col = grey(0.9))
      panel.barchart(x, y, horizontal = FALSE, stack = TRUE,
        groups = groups, subscripts = subscripts, col = col, ...)
    }
  )

print(plot_underutil_clusters)
```

We can see that the trends are similar for all substrates: Most of the enzyme mass ends up in *growth function*, the group where enzyme abundance increases with growth rate for experiment and simulation. Interestingly, the formate condition shows not only higher utilization, which can be an artifact of simulated higher growth rate for a given substrate uptake rate. But it also shows better correlation with model predictions, particularly the True positive reactions (correlated with growth in prediction and experiment). Typical growth-related reactions are also mainly collected in *growth function*, while some amino acid biosynthesis related reactions end up in the last group *unmodeled growth function*. Those correlate with growth in experiment, but are not used in model.

### Combined figure for underutilization

```{r, message = FALSE, fig.width = 7.5, fig.height = 5}
# Plot Calvin cycle reactions as example
plot_underutil_calvin <- df_prot_comp %>%
  
  # select only subset of reactions
  filter(reaction_id %in% calvin[-c(5,8:12)]) %>%
  
  xyplot(mass_g_gDCW + predicted_mass_g_gDCW ~ factor(growth_rate) | 
      reaction_id * substrate, .,
    par.settings = custom.colorblind(),
    scales = list(alternating = FALSE, x = list(at = c(2,4))), 
    as.table = TRUE,
    between = list(x = 0.5, y = 0.5),
    pch = 19, lwd = 2,
    xlab = expression("µ [h"^-1*"]"),
    ylab = expression("m"[protein]*" [g gDCW"^-1*"]"),
    ylim = c(-0.002, 0.03),
    panel = function(x, y, ...) {
      panel.grid(h = -1, v = -1, col = grey(0.9))
      panel.errbars(x, y, ewidth = 0, ...)
      panel.key(c("total protein", "utilized protein", "under-utilized protein"), cex = 0.7)
      panel.superpose(x, y, ...)},
    panel.groups = function(x, y, ...) {
      panel.lmline(x, y, ...)
    }
  )

plot_underutil_calvin <- plot_underutil_calvin + as.layer(
  xyplot(unutilized_mass_g_gDCW ~ factor(growth_rate) | 
    reaction_id * substrate,
  data = df_prot_comp %>%
    filter(reaction_id %in% calvin[-c(5,8:12)]) %>%
    group_by(substrate, growth_rate, reaction_id) %>%
    summarize(unutilized_mass_g_gDCW = mean(unutilized_mass_g_gDCW)),
  col = grey(0.5, 0.3), border = NA,
  panel = function(x, y, ...) {
    panel.xyarea(x, y, ...)
  })
)

plot_underutil_calvin <- useOuterStrips(plot_underutil_calvin)
print(plot_underutil_calvin)
```


```{r, message = FALSE, fig.width = 7.5, fig.height = 9}
print(plot_underutil_clusters, position = c(0, 0.31, 1, 0.71), more = TRUE)
print(plot_underutil_by_pw, position = c(0, -0.02, 1, 0.37))

# also export same image as svg file
svg("../figures/figure_underutilization_basic.svg", width = 7.5, height = 9)
print(plot_underutil_clusters, position = c(0, 0.31, 1, 0.71), more = TRUE)
print(plot_underutil_by_pw, position = c(0, -0.02, 1, 0.37))
dev.off()
```


## Yield-growth rate tradeoff under mixotrophic growth?

It was experimentally observed before that *R. eutropha* expresses Rubisco and other *cbb*-operon located genes even on growth on fructose or other heterotrophic substrates. Bowien et al., 1990, show that Rubisco activity can be found under growth on fructose, but on pyruvate. Dangle & Tabita, 2015, review the regulation by CbbR type regulators among others also in *R. eutropha* and mention that citrate also leads to activation of *cbb* expression. They hypothesize that ribulose bisphosphate (RuBP) is an activating effector while other central metabolism intermediates such as phosphoenol pyruvate (PEP) are repressing effector molecules. It was speculated in Bowien et al. that regulation by cbbR might actually be a repression-derepression rather than activation, which means that the default state would be a bound cbbR repressing the *cbb* operon. However it became clear that this is not the case. Shimizu et al., 2015, knocked the cbbR gene out and the result was reduced expression of *cbb* genes by 100 fold. This proves that cbbR is a required activator and not a repressor of cbb, otherwise cbbR deletion would lead to constitutive activation of cbb expression.

They same group speculated in their study that the additional Rubisco expression could have a benefit for carbon yield, specifically for product yield of PHB. They show that PHB from the WT contains slightly more 13C labeled mass (and total mass) than the cbbR and cbbS/L knockouts. This means that the cell would have a (product or biomass) yield advantage by Rubisco expression on fructose, so called mixotrophic growth.

The following section tests the hypothesis of a yield-growth rate tradeoff with the resource allocation model. First simulation data from the RBA model is imported

```{r}
#adjust path
mixotroph_dir <- gsub("substrate_limitation", "mixotrophy", simulation_dir)

# read simulation results
df_mixflux <- read_rba_result(list.files(mixotroph_dir, pattern = "fluxes_.*.tsv$", full.names = TRUE))
df_mixmacr <- read_rba_result(list.files(mixotroph_dir, pattern = "macroprocesses_.*.tsv", full.names = TRUE))
```

The next part is to compare yield, growth rate, CO2 emission and other fluxes for a range of simulations where Rubisco was forced to re-fix emitted CO2 from growth on fructose. Simulations were performed for increasing flux through Rubisco from 0 to 5 mmol gDCW-1 h-1.

```{r, fig.width = 5, fig.height = 3}
# rename column
df_mixmacr <- df_mixmacr %>% rename(CO2_refixation = sim_run)

xyplot(value ~ as.factor(CO2_refixation) | key,
  filter(df_mixmacr, key %in% c("mu", "yield")),
  scales = list(alternating = FALSE), ylim = c(0, 0.6),
  between = list(x = 0.5, y = 0.5),
  par.settings = custom.colorblind(), lwd = 2,
  xlab = expression("forced CO2 refixation [mmol h"^-1*"gDCW"^-1*"]"),
  ylab = expression("µ / Y"),
  panel = function(x, y, ...) {
    panel.grid(h = -1, v = -1, col = grey(0.9))
    panel.xyplot(x, y, ...)
  }
)
```
There is no increase in growth rate or yield possible according to the RBA model. The yield is in fact calculated based on the growth rate µ and the substrate uptake rate qS. If qS is kept constant, yield and growth rate depend on each other in the relation Y [gDCW/gS] = µ [h-1] / qS [gS gDCW-1 h-1]. Therefore, the model was also allowed to have variable substrate uptake rate (but fixed initial substrate concentration) but it did not make a difference. The model actually calculates already a high-yield phenotype and if CO2 re-fixation would have had an advantage for growth, it might have been detected earlier depending on the protein costs for the respective pathway. Before a final verdict, we can follow the fate of the fixed CO2 through the metabolism.

```{r, fig.width = 5, fig.height = 5}
# rename column
df_mixflux <- df_mixflux %>% rename(CO2_refixation = sim_run)

xyplot(abs(value) ~ as.factor(CO2_refixation) | factor(key, unique(key)[c(4,8,9,6,7,3,5,1,2)]),
  filter(df_mixflux, key %in% c("CO2t", "RBPC", "PRUK", "FruABC", "EDD", "EDA", "TKT1", "CS", "AKGDH", "O2t")),
  scales = list(alternating = FALSE),
  between = list(x = 0.5, y = 0.5), as.table = TRUE,
  par.settings = custom.colorblind(), lwd = 2,
  xlab = expression("forced CO2 refixation [mmol h"^-1*"gDCW"^-1*"]"),
  ylab = expression("flux [mmol h"^-1*"gDCW"^-1*"]"),
  panel = function(x, y, ...) {
    panel.grid(h = -1, v = -1, col = grey(0.9))
    panel.xyplot(x, y, ...)
  }
)
```

It becomes clear that yield and growth rate decrease, and not increase, with additional CO2 fixation, because:

- energy requirement for CO2 fixation leads to lower flux through ED pathway, but higher flux through TCA
- this is in order to generate the required NADH/ATP for CO2 fixation
- respiration and O2 consumption also increases with forced mixotrophic growth
- there is no net reduction of CO2 emission. In fact cells emit more CO2 even when they fix some of it due to increased energy requirement
- storing some of the fixed CO2 as PHB would not increase biomass yield as additional energy requirement still persists
- cells should not be able to make more PHB using this strategy, regardless of biomass yield. If acetyl-CoA is drained for PHB, even less energy is made available through TCA and OXPHOS.



